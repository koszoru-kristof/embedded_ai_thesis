\chapter{Background}
\label{chapter:background} 

% \emph{[Literature review: ESC findings - Enviromental Sound Classification (also embedded implementations), VAD findings - Voice Activity Detection, PIR room occupancy research, keyword spotting, Edge AI?]}
% \bigskip

% Probably you should change the title to something that describes more the content of this chapter. Background consists of information that help other masters of the same degree program to understand the rest of the thesis. Often the background has two parts: the first part tells the theoretical background and the second one describes the background tied to the implementation.


% LAURAA
% too long etc..
% In Chapter 2, you should try to fit the intro to the chapter (before 2.1 begins) in one paragraph.  In my opinion, it is not necessary to discuss the contents of subsubchapters (2.1.x) in the opening.  
% Contents of 3.1.1. would perhaps fit better in 2.1 because now you discuss PIR problems before telling much about what PIR is and how it works. 

%the three main topics
% - Acoustic Scene Classification
% - Room occupancy 
% - Edge-AI
 
This chapter provides a general introduction to research areas and insights closely related to the thesis topic.
%Moving on, the remaining part of the chapter presents the latest scientific achievements and industrial best practises in presence detection and information extraction from audio.
The Acoustic Scene Classification section will give a general overview of the latest research publications and most common industrial approaches dedicated to high-level information extraction from audio.

After the general introduction to the strictly sound-related research,we are going to narrow our focus to Room Occupancy research outcomes, detecting or counting people in indoor environments. Providing an overview on the various sensors researchers historically tested in different scenarios and their usability in several situations.

%More importantly with a special focus on Environmental Sound Classification and Voice Activity Detection research fields, which are the closest to the problem description of the thesis. These well-established fields had a great impact on the applied technologies and their well organized datasets and ready made solutions provided a clear guidance in the development of the audio processing part of the project. 

Some of the papers describe the implementation and test results of the developed algorithms on embedded platforms too, which helps to position the problem in the computational complexity and feasibility space. The increased computational requirement for novel deep learning model inference on edge devices often imposes a hard limit for real-time usability.


Finally, a short overview of Edge-AI will close the chapter, since in most cases the incentive is to run the advanced machine learning algorithms exclusively on embedded level. Given that it is an early stage but rapidly evolving field, the aim is to provide an overall picture of the capabilities and hard limitations using this approach.




\section{Acoustic Scene Classification}

Extracting high-level information from a given audio flow is a well-researched area with recent breakthroughs in many fields including Automatic Speech Recognition (ASR) to convert the live speech to text, Speaker Recognition, or Speech Separation using end-to-end Deep learning. Human presence can be associated with many different types of noises in indoor office environments. Speech is the most obvious one but even silent work with computers involves noises like typing, footsteps, breathing, and many others which might also reveal room occupancy. Among the mentioned alternatives, detection of speech will be the focus of the thesis, given it is the easiest and loudest signal for a human listener to differentiate between an occupied and an unoccupied meeting room. Moreover, speech frequencies and tones are characteristic of people while squeaking noises can be generated by other sources outside the examined area leading to false predictions.

In the next sections, we will exclusively concentrate on research fields where the goal is to spot human voice regardless of the content of the speech. The problem definition is simpler than for most recognition tasks, but could be sufficient for the scope of the thesis, where the meaning of the speech is considered to be irrelevant.

% Consider if you want to explain why and how detecting speech was selected. The "ultimate goal" would be spot "all" voices created by human presence (like typing, steps, chair noise or even breathing) but spotting pure speech was chosen to be in the scope of the thesis.

\subsection{Environmental Sound Classification (ESC)}
The goal of ESC is to classify audio recordings with a given length into one of the predefined classes which best describes the environment it was recorded in. The ESC-50 dataset \cite{ESC_dataset} is a labeled collection of audio samples for 50 categories, ranging from various animal, human and natural soundscapes to urban noises.A subset of the collection will be beneficial for training our DNN models in a different context and some of the research findings can also be translated into our domain.

\subsection{Voice Activity Detection (VAD)}
The Voice Activity Detector can be often found as one of the first modules in Automatic Speech Recognition (ASR) algorithms. Its only function is to detect at the lowest cost whether the audio stream contains speech or not, which needs to be further processed by more resource-intensive functions.

Approaches involve Gaussian Mixture Models (GMM) \cite{reynolds2009gaussianMM} and Hidden Markov Models (HMM) \cite{eddy2004hiddenMM}, like in the WebRTC VAD \cite{webrtc_vad}, developed by Google for real-time communication through the internet. Although their relatively simple architecture made it possible to run constantly in the background with low computational cost, they often face difficulties to spot speech in noisy environments. To overcome this issue modern VADs usually apply deep neural network models after feature extraction in the frequency domain. Test results are suggesting that both feed-forward and recurrent neural network structures can produce accurate predictions for the task \cite{sehgal18convolutional_vad}, although computationally heavy networks can be impractical for real-time embedded inference, regardless of their high accuracy.

% VAD sources:
% https://github.com/nicklashansen/voice-activity-detection
% https://github.com/nicklashansen/voice-activity-detection/blob/master/vad.ipynb
% https://github.com/hcmlab/vadnet

% WebRTC VAD
% https://webrtc.github.io/samples/
% https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API

The QUT-NOISE \cite{qut_noise} background noise, and the TIMIT \cite{timit} clean speech corpus serve as the base for constructing the QUT-NOISE-TIMIT dataset as well known training dataset and benchmark for VAD algorithms. Following the provided procedure over 600 hours of audio can be generated by mixing the noise and speech files with various target signal-to-noise ratios (SNR).

\section{Room occupancy detection research}

%input
Earlier research tackles the presence detection problem using a wide variety of sensors ranging from the conventional PIR, CO2, camera, sound, and environmental sensors to alternative, indirect approaches, mostly based on network activity and electricity usage. Cameras are generally used in this context only to establish only the ground truth for learning-based methods for other types of sensors, due to their high intrusiveness. \autoref{tab:comp_sensor} provides an overview of the most recent sensor technologies in research and their current capabilities. 

%sensor alternatives literature overview
% \cite{build_occ_det_tech_review}, algorithms
% \cite{build_occ_det_tech_review_sensor} - sensors

\begin{table}[]
\centering
\begin{adjustbox}{max width=0.95\textwidth}
\begin{tabular}{lllll}
\hline
\textbf{Sensor type}           & \textbf{Intrusiveness} & \textbf{Cost} & \textbf{Level of occupancy}                  & \textbf{References} \\ \hline
PIR                            & Low           & Low  & Presence, location                   & \cite{Naray15PIR_loc, PIR_only_behav_ext,PIR_only_behav_ext_mcu,PIR_tracking_yang2019new}          \\
CO\textsubscript{2}                            & Low           & Low  & Presence, location, count, activity  &  \cite{Yang12multisensor_aud,Newsh10PIR_CO2, CALI2015co2_anal}          \\
Camera                         & High          & High & Presence, location, count, activity, &  \cite{SHIH2014camera}          \\
                               &               &      & \hspace{0.5cm}tracking, identity     &            \\
Ultrasonic                     & Low           & Low  & Presence, location                   &  \cite{Shih16ultrason}           \\
Sound                          & Medium        & Low  & Presence, location                   & 
\cite{Aud_crowd_entropy_Chen, Aud_crowd_ste_huang, aud_gm_hmm, Yang12multisensor_aud}           \\
Environmental                  & Low           & Low  & Presence                             &   \cite{Yang12multisensor_aud}         \\
Tag based (Alt.)               & Low           & Low  & Presence, count, identity, location  &  \cite{Li16rfid_occ}           \\
Smart device based (Alt.)      & High          & High & Presence, location, count, activity, &   \cite{Gupta13WIFI_occ}         \\
                               &               &      & \hspace{0.5cm}tracking, identity     &            \\
Network activity based (Alt.)  & High          & Low  & Presence, count, location, identity  &   \cite{Newsh10PIR_CO2}         \\
                               &               &      & \hspace{0.5cm}activity               &            \\
Electricity usage based (Alt.) & Low           & High & Presence, location, activity         &   \cite{Newsh10PIR_CO2}           \\ \hline
\end{tabular}
\end{adjustbox}
\caption{Comparison of sensing approaches in occupancy detection research, adapted from \cite{build_occ_det_tech_review_sensor}.}
\label{tab:comp_sensor}
\end{table}



%alg
\begin{sloppypar}
Rueda et al. \cite{build_occ_det_tech_review} grouped the occupancy detection algorithms into three main categories in their literature review: analytical, data-driven, and knowledge-based. Analytical techniques aim to construct a mathematical relationship between the occupancy state and the measured sensor values. Cali et al. \cite{CALI2015co2_anal} developed a dynamic model for approximating the number of occupants by the measured CO\textsubscript{2} concentration in the room and predicted correctly 80.6\% of the time in their test environments.
\end{sloppypar}

Data-driven solutions often involved various modeling tools such as infinite hidden Markov model (iHMM) \cite{rasmussen1999infiniteGM}, hidden Markov model (HMM), k-means clustering \cite{hartigan1979kmeansclus, likas2003globalkmeansclus}, Support Vector Machines (SVM) \cite{noble2006supportVM}, Bayesian inference, and artificial neural network approaches \cite{Yang12multisensor_aud, UCI_nn_real_time}. Agarwal et al. \cite{rajesh10occ_rules} designed a knowledge-based system with magnetic door sensors and PIR sensor modules and managed to detect occupancy correctly with the predefined rules for expected system behavior.

%output
Occupancy detection systems can be divided into two general categories related to their measurement output. Simpler presence detectors can only indicate human presence as binary information (0 or 1), while more complex systems are able to classify the number of people, their location, identity, current activity, or even the direction of motion in the examined area, depending on the applied sensors and data processing approaches.



\subsection{PIR only}
It has been a growing effort to extract occupancy count, movement direction, human position, and behavioral features based on the analog output of a single or multiple PIR sensors arranged in a predefined way across the given space. 

Raykov et al. \cite{PIR_only_behav_ext} demonstrated that occupancy count can be extracted with $\pm$ 1 individual accuracy even from a single analog PIR sensor output by modeling the PIR output with Laplace distributions and clustering it with infinite hidden Markov model (iHMM) to group similar patterns. The approach worked best in cases of less than 8 people with a relatively long, 20 minutes applied time window.
% https://publications.aston.ac.uk/id/eprint/29352/1/Predicting_room_occupancy_with_a_PIR_sensor_through_behavior_extraction.pdf
They also provide a real-time microcontroller-based solution \cite{PIR_only_behav_ext_mcu} achieving more than 80\% accuracy on 1500 samples for a 30 seconds window while consuming less than 50 mW.
% https://www.researchgate.net/publication/314151438_Real-time_Room_Occupancy_Estimation_with_Bayesian_Machine_Learning_using_a_Single_PIR_Sensor_and_Microcontroller

Yang et al. \cite{PIR_tracking_yang2019new} used the analog PIR data from multiple sensors to estimate the azimuth angle of a moving person and with multiple sensor predictions localize it in a predefined area. The average localization error was strictly decreasing as they added more sensors to the experiment and reached as low as 0.63m with 4 sensors applied. Narayana et al. \cite{Naray15PIR_loc} built an array of PIR sensors and also with analog signal processing techniques managed to classify moving objects and localize them with 30 cm accuracy with 80 \% confidence in 5 m range.
% https://arxiv.org/pdf/1901.10700.pdf


\subsection{Sound only}
Solely microphone-based research in this domain mainly aims to estimate crowd size by extracting various features from the audio signal. One naive approach assumes that all the participants are speaking relatively at the same time and in this case the energy of the recorded signal will be proportional with the number of people. While more advanced solutions compute the Mel-Frequency features to better distinguish speech from general noise produced by non-human sources.

Huang et al. \cite{Aud_crowd_ste_huang} proposed a crowd size estimation technique based on Short-Time Energy (STE) computed on a 50 ms window, and tested it in a simulated environment using the TIMIT speech dataset \cite{timit} modeling the size of the room and the relative position of people to the microphone. The simulation only used clear recordings of people and did not take the room acoustics into account. For increased robustness, they fit a probability density function of data collected for 5 or 20 seconds and classify with respect to the maximal value and the theoretically established baseline derived from the simulation parameters. While in the following paper Huang  \cite{Aud_sound_cancellation} lays down an approach for noisy environments using background noise cancellation before the STE computation which leads to an 11\% increase in average detection accuracy.
% https://core.ac.uk/download/pdf/60582955.pdf
% https://www.mdpi.com/2075-5309/8/6/78?type=check_update&version=1
Chen et al. \cite{Aud_crowd_entropy_Chen} proposed an entropy-based method for the same problem.
% https://www.isca-speech.org/archive/Interspeech_2017/pdfs/0070.PDF

Valle in \cite{aud_gm_hmm} developed algorithms based on their audio dataset collected in a retail shop with a smartphone and labeled with the help of Amazon's Mechanical Turk. For the people counting prediction, the Mel-Frequency Cepstral Coefficients (MFCC) and their first and second deltas turned to be the most useful in their analysis. Given a total of 60 features (20+20+20) as an input to the Gaussian Mixtures and Hidden Markov Model (GM-HMM) the algorithm was able to predict occupancy up to 200 people reasonably accurately.
% https://www.researchgate.net/publication/305655038_ABROA_Audio-Based_Room-Occupancy_Analysis_using_Gaussian_Mixtures_and_Hidden_Markov_Models


\subsection{Multisensor based}
\label{section:Multisensor_research}
More recent research uses multiple environmental sensor sources for the hope of increased reliability and robustness in occupancy prediction. Even if the new sensor measurements such as light level or temperature would not be sufficient for presence detection on their own, but they can contribute new features for the final prediction model.

Candanedo et al. \cite{UCI_occ_dataset_pred} collected temperature, relative humidity, light, CO\textsubscript{2} levels and computed a humidity ratio in a test office room while a camera recorded the true occupancy for model fitting purposes. They have published the data set freely available on the UCI University domain. Their methods involved Linear Discriminant Analysis (LDA), Classification and Regression Trees (CART), and Random Forests (RF) reaching 95\%$+$ accuracy in their environment. However, since the lights were manually operated during the experiment it features an overwhelmingly high correlation with the occupancy, but with a false sense of confidence. The final models could not be used in different environments or controlling the lights based on occupancy, like in our case, since nobody would give this reliable input with a manual light switch.
% https://www.researchgate.net/publication/285627413_Accurate_occupancy_detection_of_an_office_room_from_light_temperature_humidity_and_CO2_measurements_using_statistical_learning_models
% nice comparison of previous approaches

There have been various developments on the same data set introducing deep learning methods for performance improvements. Liu et al. \cite{UCI_autoencoder}  first trained a sparse Auto-encoder structure for feature extraction before the Support Vector Machine (SVM) and Liblinear classifiers, while simple Feed-forward Neural Networks were used in \cite{UCI_nn_real_time}.
% https://ieeexplore.ieee.org/document/7912203



\section{EDGE-AI}
The constant improvements of embedded hardware performance and efficiency have opened the door for a new era of computing in machine learning, which focuses on local data processing for inference, eliminating the need for cloud computation and data streaming. Although current Edge AI solutions \cite{chen2019deep_edge_review} still rely on external computation for speeding up the training process, the prediction steps can be computed on the device exclusively. Taking this approach often yields better response time than the cloud-based counterpart, due to the elimination of network and additional latency \cite{zhou2018robust_edge_ai}. Edge AI offers an elegant solution for privacy concerns too since the sensitive information does not need to leave the device, can be processed locally, and therefore devices can be designed without any network connection.

The limited processing power of microcontrollers restricts the maximal size, type, depth of artificial neural networks by a significant amount. Techniques like quantization and network pruning of trained models can reduce the computational complexity in systems without floating-point arithmetic while maintaining prediction accuracy \cite{han2016deep_quant_prun}.
%The emergence of Edge AI and the rapid improvements in hardware development opened the door for ideas which could not been possible to implement before due to computation or network constraints. 
Chip manufacturers are fueling the innovation with alternatives on low power system-on-a-chip (SoC) devices, mostly developing dedicated hardware accelerators for AI inference purposes. This initiative can manifest in various forms with increased memory and bandwidth for Deep Learning model weights and dedicated matrix multipliers for a reduced delay in forward-pass.

High-performance yet affordable embedded platforms and tools motivated this work to explore the feasibility and applicability of the combination of machine learning and embedded audio processing in the presence detection space.
